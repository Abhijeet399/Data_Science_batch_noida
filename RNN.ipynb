{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCZhZWkbqoMj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JJOyaU0xiM1",
        "outputId": "7e8ba295-fb47-4a94-c6d9-b1efd0f06cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjgYJvSaxt3v",
        "outputId": "e7de627e-4f73-4eb9-876d-dfaf1179a844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25000,) (25000,) (25000,) (25000,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVhAuzTHxzmu"
      },
      "outputs": [],
      "source": [
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = max_review_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI3rGMFByhIb",
        "outputId": "88c37dd7-2677-4f6d-e634-dc4059f0ec0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000, 500)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52ZVfhsiyjJH"
      },
      "outputs": [],
      "source": [
        "embedding_vecor_length = 32\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U_azA6gyyEF",
        "outputId": "bebb1d4e-3508-4ca8-e07a-3421cf6e12db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100)               13300     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173,401\n",
            "Trainable params: 173,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model.add(Embedding(top_words, embedding_vecor_length, input_length = max_review_length))\n",
        "model.add(SimpleRNN(100, dropout = 0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nl6hDLN0daO",
        "outputId": "04028129-2e42-44dc-cc5c-f1a5f22e2ebd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "391/391 [==============================] - 127s 321ms/step - loss: 0.7101 - accuracy: 0.5073\n",
            "Epoch 2/200\n",
            "391/391 [==============================] - 123s 314ms/step - loss: 0.6981 - accuracy: 0.5109\n",
            "Epoch 3/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.6948 - accuracy: 0.5162\n",
            "Epoch 4/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.6890 - accuracy: 0.5337\n",
            "Epoch 5/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.6789 - accuracy: 0.5529\n",
            "Epoch 6/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.6539 - accuracy: 0.5973\n",
            "Epoch 7/200\n",
            "391/391 [==============================] - 123s 314ms/step - loss: 0.5596 - accuracy: 0.7075\n",
            "Epoch 8/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.6524 - accuracy: 0.6036\n",
            "Epoch 9/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.6406 - accuracy: 0.6194\n",
            "Epoch 10/200\n",
            "391/391 [==============================] - 120s 308ms/step - loss: 0.6187 - accuracy: 0.6461\n",
            "Epoch 11/200\n",
            "391/391 [==============================] - 121s 308ms/step - loss: 0.5958 - accuracy: 0.6690\n",
            "Epoch 12/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5736 - accuracy: 0.6904\n",
            "Epoch 13/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5625 - accuracy: 0.7005\n",
            "Epoch 14/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.5650 - accuracy: 0.6998\n",
            "Epoch 15/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.5391 - accuracy: 0.7254\n",
            "Epoch 16/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5097 - accuracy: 0.7556\n",
            "Epoch 17/200\n",
            "391/391 [==============================] - 120s 308ms/step - loss: 0.4873 - accuracy: 0.7748\n",
            "Epoch 18/200\n",
            "391/391 [==============================] - 120s 308ms/step - loss: 0.4766 - accuracy: 0.7843\n",
            "Epoch 19/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.4593 - accuracy: 0.7960\n",
            "Epoch 20/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.4521 - accuracy: 0.7986\n",
            "Epoch 21/200\n",
            "391/391 [==============================] - 121s 308ms/step - loss: 0.4365 - accuracy: 0.8113\n",
            "Epoch 22/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.4228 - accuracy: 0.8196\n",
            "Epoch 23/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.4177 - accuracy: 0.8217\n",
            "Epoch 24/200\n",
            "391/391 [==============================] - 121s 311ms/step - loss: 0.4067 - accuracy: 0.8255\n",
            "Epoch 25/200\n",
            "391/391 [==============================] - 120s 306ms/step - loss: 0.4043 - accuracy: 0.8233\n",
            "Epoch 26/200\n",
            "391/391 [==============================] - 120s 308ms/step - loss: 0.3967 - accuracy: 0.8309\n",
            "Epoch 27/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.4038 - accuracy: 0.8270\n",
            "Epoch 28/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4214 - accuracy: 0.8110\n",
            "Epoch 29/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3998 - accuracy: 0.8307\n",
            "Epoch 30/200\n",
            "391/391 [==============================] - 120s 307ms/step - loss: 0.3855 - accuracy: 0.8385\n",
            "Epoch 31/200\n",
            "391/391 [==============================] - 121s 308ms/step - loss: 0.5101 - accuracy: 0.7610\n",
            "Epoch 32/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4725 - accuracy: 0.7876\n",
            "Epoch 33/200\n",
            "391/391 [==============================] - 120s 307ms/step - loss: 0.4367 - accuracy: 0.8108\n",
            "Epoch 34/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.5668 - accuracy: 0.6812\n",
            "Epoch 35/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.5841 - accuracy: 0.6595\n",
            "Epoch 36/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5737 - accuracy: 0.6702\n",
            "Epoch 37/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.5642 - accuracy: 0.6794\n",
            "Epoch 38/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5616 - accuracy: 0.6849\n",
            "Epoch 39/200\n",
            "391/391 [==============================] - 120s 308ms/step - loss: 0.5498 - accuracy: 0.6999\n",
            "Epoch 40/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5400 - accuracy: 0.7127\n",
            "Epoch 41/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5239 - accuracy: 0.7275\n",
            "Epoch 42/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.5066 - accuracy: 0.7439\n",
            "Epoch 43/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4810 - accuracy: 0.7682\n",
            "Epoch 44/200\n",
            "391/391 [==============================] - 121s 311ms/step - loss: 0.4632 - accuracy: 0.7826\n",
            "Epoch 45/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.4414 - accuracy: 0.7984\n",
            "Epoch 46/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4235 - accuracy: 0.8133\n",
            "Epoch 47/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4431 - accuracy: 0.7936\n",
            "Epoch 48/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5305 - accuracy: 0.7201\n",
            "Epoch 49/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.4805 - accuracy: 0.7666\n",
            "Epoch 50/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4791 - accuracy: 0.7641\n",
            "Epoch 51/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.5081 - accuracy: 0.7359\n",
            "Epoch 52/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.4500 - accuracy: 0.7917\n",
            "Epoch 53/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4217 - accuracy: 0.8186\n",
            "Epoch 54/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.4195 - accuracy: 0.8113\n",
            "Epoch 55/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4204 - accuracy: 0.8125\n",
            "Epoch 56/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3891 - accuracy: 0.8320\n",
            "Epoch 57/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3772 - accuracy: 0.8392\n",
            "Epoch 58/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3747 - accuracy: 0.8405\n",
            "Epoch 59/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3675 - accuracy: 0.8445\n",
            "Epoch 60/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3581 - accuracy: 0.8497\n",
            "Epoch 61/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3568 - accuracy: 0.8494\n",
            "Epoch 62/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3887 - accuracy: 0.8326\n",
            "Epoch 63/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3979 - accuracy: 0.8248\n",
            "Epoch 64/200\n",
            "391/391 [==============================] - 122s 313ms/step - loss: 0.4978 - accuracy: 0.7446\n",
            "Epoch 65/200\n",
            "391/391 [==============================] - 123s 315ms/step - loss: 0.3786 - accuracy: 0.8380\n",
            "Epoch 66/200\n",
            "391/391 [==============================] - 123s 314ms/step - loss: 0.4010 - accuracy: 0.8177\n",
            "Epoch 67/200\n",
            "391/391 [==============================] - 123s 316ms/step - loss: 0.4427 - accuracy: 0.7858\n",
            "Epoch 68/200\n",
            "391/391 [==============================] - 123s 315ms/step - loss: 0.3912 - accuracy: 0.8261\n",
            "Epoch 69/200\n",
            "391/391 [==============================] - 123s 316ms/step - loss: 0.4180 - accuracy: 0.7993\n",
            "Epoch 70/200\n",
            "391/391 [==============================] - 123s 315ms/step - loss: 0.3463 - accuracy: 0.8568\n",
            "Epoch 71/200\n",
            "391/391 [==============================] - 122s 313ms/step - loss: 0.3371 - accuracy: 0.8570\n",
            "Epoch 72/200\n",
            "391/391 [==============================] - 124s 316ms/step - loss: 0.3310 - accuracy: 0.8634\n",
            "Epoch 73/200\n",
            "391/391 [==============================] - 123s 314ms/step - loss: 0.3428 - accuracy: 0.8532\n",
            "Epoch 74/200\n",
            "391/391 [==============================] - 123s 314ms/step - loss: 0.3614 - accuracy: 0.8462\n",
            "Epoch 75/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3660 - accuracy: 0.8408\n",
            "Epoch 76/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3578 - accuracy: 0.8551\n",
            "Epoch 77/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4466 - accuracy: 0.7991\n",
            "Epoch 78/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5457 - accuracy: 0.7078\n",
            "Epoch 79/200\n",
            "391/391 [==============================] - 122s 313ms/step - loss: 0.5678 - accuracy: 0.6822\n",
            "Epoch 80/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.5606 - accuracy: 0.6926\n",
            "Epoch 81/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5636 - accuracy: 0.6884\n",
            "Epoch 82/200\n",
            "391/391 [==============================] - 121s 311ms/step - loss: 0.5682 - accuracy: 0.6764\n",
            "Epoch 83/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.5728 - accuracy: 0.6708\n",
            "Epoch 84/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5693 - accuracy: 0.6733\n",
            "Epoch 85/200\n",
            "391/391 [==============================] - 122s 313ms/step - loss: 0.5698 - accuracy: 0.6694\n",
            "Epoch 86/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5660 - accuracy: 0.6780\n",
            "Epoch 87/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5667 - accuracy: 0.6756\n",
            "Epoch 88/200\n",
            "391/391 [==============================] - 123s 313ms/step - loss: 0.5662 - accuracy: 0.6748\n",
            "Epoch 89/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.5635 - accuracy: 0.6734\n",
            "Epoch 90/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5629 - accuracy: 0.6732\n",
            "Epoch 91/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5617 - accuracy: 0.6755\n",
            "Epoch 92/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5570 - accuracy: 0.6862\n",
            "Epoch 93/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5599 - accuracy: 0.6821\n",
            "Epoch 94/200\n",
            "391/391 [==============================] - 121s 311ms/step - loss: 0.5534 - accuracy: 0.6869\n",
            "Epoch 95/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.5479 - accuracy: 0.6943\n",
            "Epoch 96/200\n",
            "391/391 [==============================] - 122s 313ms/step - loss: 0.5551 - accuracy: 0.6816\n",
            "Epoch 97/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.5565 - accuracy: 0.6847\n",
            "Epoch 98/200\n",
            "391/391 [==============================] - 123s 314ms/step - loss: 0.5544 - accuracy: 0.6874\n",
            "Epoch 99/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5463 - accuracy: 0.6958\n",
            "Epoch 100/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5545 - accuracy: 0.6922\n",
            "Epoch 101/200\n",
            "391/391 [==============================] - 122s 313ms/step - loss: 0.5300 - accuracy: 0.7204\n",
            "Epoch 102/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.5536 - accuracy: 0.6898\n",
            "Epoch 103/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.5504 - accuracy: 0.6889\n",
            "Epoch 104/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.5018 - accuracy: 0.7408\n",
            "Epoch 105/200\n",
            "391/391 [==============================] - 122s 313ms/step - loss: 0.4554 - accuracy: 0.7728\n",
            "Epoch 106/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4864 - accuracy: 0.7522\n",
            "Epoch 107/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4743 - accuracy: 0.7630\n",
            "Epoch 108/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4574 - accuracy: 0.7791\n",
            "Epoch 109/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4360 - accuracy: 0.7971\n",
            "Epoch 110/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4151 - accuracy: 0.8159\n",
            "Epoch 111/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3970 - accuracy: 0.8276\n",
            "Epoch 112/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3862 - accuracy: 0.8306\n",
            "Epoch 113/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3977 - accuracy: 0.8203\n",
            "Epoch 114/200\n",
            "391/391 [==============================] - 121s 311ms/step - loss: 0.3721 - accuracy: 0.8405\n",
            "Epoch 115/200\n",
            "391/391 [==============================] - 121s 311ms/step - loss: 0.4334 - accuracy: 0.7901\n",
            "Epoch 116/200\n",
            "391/391 [==============================] - 120s 308ms/step - loss: 0.3892 - accuracy: 0.8240\n",
            "Epoch 117/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3501 - accuracy: 0.8528\n",
            "Epoch 118/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3815 - accuracy: 0.8307\n",
            "Epoch 119/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4199 - accuracy: 0.8111\n",
            "Epoch 120/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4044 - accuracy: 0.8179\n",
            "Epoch 121/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3820 - accuracy: 0.8295\n",
            "Epoch 122/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.4477 - accuracy: 0.7903\n",
            "Epoch 123/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3941 - accuracy: 0.8235\n",
            "Epoch 124/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3834 - accuracy: 0.8326\n",
            "Epoch 125/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3566 - accuracy: 0.8473\n",
            "Epoch 126/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3887 - accuracy: 0.8319\n",
            "Epoch 127/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4156 - accuracy: 0.8268\n",
            "Epoch 128/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4358 - accuracy: 0.8119\n",
            "Epoch 129/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4249 - accuracy: 0.8158\n",
            "Epoch 130/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.4079 - accuracy: 0.8246\n",
            "Epoch 131/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3993 - accuracy: 0.8294\n",
            "Epoch 132/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3919 - accuracy: 0.8304\n",
            "Epoch 133/200\n",
            "391/391 [==============================] - 123s 314ms/step - loss: 0.3881 - accuracy: 0.8316\n",
            "Epoch 134/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3809 - accuracy: 0.8359\n",
            "Epoch 135/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3804 - accuracy: 0.8352\n",
            "Epoch 136/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4534 - accuracy: 0.7944\n",
            "Epoch 137/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3924 - accuracy: 0.8308\n",
            "Epoch 138/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3753 - accuracy: 0.8383\n",
            "Epoch 139/200\n",
            "391/391 [==============================] - 121s 311ms/step - loss: 0.4052 - accuracy: 0.8236\n",
            "Epoch 140/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4162 - accuracy: 0.8200\n",
            "Epoch 141/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3709 - accuracy: 0.8391\n",
            "Epoch 142/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3640 - accuracy: 0.8456\n",
            "Epoch 143/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3832 - accuracy: 0.8363\n",
            "Epoch 144/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3702 - accuracy: 0.8385\n",
            "Epoch 145/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3891 - accuracy: 0.8287\n",
            "Epoch 146/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3628 - accuracy: 0.8428\n",
            "Epoch 147/200\n",
            "391/391 [==============================] - 122s 313ms/step - loss: 0.3549 - accuracy: 0.8478\n",
            "Epoch 148/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3537 - accuracy: 0.8484\n",
            "Epoch 149/200\n",
            "391/391 [==============================] - 121s 311ms/step - loss: 0.3983 - accuracy: 0.8279\n",
            "Epoch 150/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3635 - accuracy: 0.8414\n",
            "Epoch 151/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3521 - accuracy: 0.8490\n",
            "Epoch 152/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3512 - accuracy: 0.8476\n",
            "Epoch 153/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3459 - accuracy: 0.8542\n",
            "Epoch 154/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3469 - accuracy: 0.8532\n",
            "Epoch 155/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3688 - accuracy: 0.8438\n",
            "Epoch 156/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3974 - accuracy: 0.8230\n",
            "Epoch 157/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3745 - accuracy: 0.8376\n",
            "Epoch 158/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3829 - accuracy: 0.8381\n",
            "Epoch 159/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.4213 - accuracy: 0.8104\n",
            "Epoch 160/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.4077 - accuracy: 0.8232\n",
            "Epoch 161/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3752 - accuracy: 0.8425\n",
            "Epoch 162/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3641 - accuracy: 0.8497\n",
            "Epoch 163/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3613 - accuracy: 0.8484\n",
            "Epoch 164/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3754 - accuracy: 0.8419\n",
            "Epoch 165/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3824 - accuracy: 0.8363\n",
            "Epoch 166/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3749 - accuracy: 0.8379\n",
            "Epoch 167/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3815 - accuracy: 0.8355\n",
            "Epoch 168/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3722 - accuracy: 0.8411\n",
            "Epoch 169/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3714 - accuracy: 0.8403\n",
            "Epoch 170/200\n",
            "391/391 [==============================] - 120s 308ms/step - loss: 0.3673 - accuracy: 0.8430\n",
            "Epoch 171/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3591 - accuracy: 0.8442\n",
            "Epoch 172/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3626 - accuracy: 0.8443\n",
            "Epoch 173/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3427 - accuracy: 0.8523\n",
            "Epoch 174/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3626 - accuracy: 0.8481\n",
            "Epoch 175/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3517 - accuracy: 0.8537\n",
            "Epoch 176/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3366 - accuracy: 0.8596\n",
            "Epoch 177/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3489 - accuracy: 0.8531\n",
            "Epoch 178/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3333 - accuracy: 0.8650\n",
            "Epoch 179/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3366 - accuracy: 0.8593\n",
            "Epoch 180/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3234 - accuracy: 0.8621\n",
            "Epoch 181/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3363 - accuracy: 0.8567\n",
            "Epoch 182/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3746 - accuracy: 0.8418\n",
            "Epoch 183/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3573 - accuracy: 0.8514\n",
            "Epoch 184/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3786 - accuracy: 0.8377\n",
            "Epoch 185/200\n",
            "391/391 [==============================] - 122s 311ms/step - loss: 0.3643 - accuracy: 0.8479\n",
            "Epoch 186/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3578 - accuracy: 0.8519\n",
            "Epoch 187/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3551 - accuracy: 0.8540\n",
            "Epoch 188/200\n",
            "391/391 [==============================] - 121s 309ms/step - loss: 0.3536 - accuracy: 0.8543\n",
            "Epoch 189/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3525 - accuracy: 0.8542\n",
            "Epoch 190/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3500 - accuracy: 0.8524\n",
            "Epoch 191/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3459 - accuracy: 0.8553\n",
            "Epoch 192/200\n",
            "391/391 [==============================] - 120s 308ms/step - loss: 0.3419 - accuracy: 0.8598\n",
            "Epoch 193/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3685 - accuracy: 0.8449\n",
            "Epoch 194/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3468 - accuracy: 0.8526\n",
            "Epoch 195/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3350 - accuracy: 0.8515\n",
            "Epoch 196/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3233 - accuracy: 0.8624\n",
            "Epoch 197/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3187 - accuracy: 0.8642\n",
            "Epoch 198/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3159 - accuracy: 0.8654\n",
            "Epoch 199/200\n",
            "391/391 [==============================] - 122s 312ms/step - loss: 0.3134 - accuracy: 0.8681\n",
            "Epoch 200/200\n",
            "391/391 [==============================] - 121s 310ms/step - loss: 0.3194 - accuracy: 0.8676\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4913114050>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs = 200, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIMrqxAU3aZR"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(X_test, y_test ,verbose=0)\n",
        "print(\"Accuracy: \", (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaOE-aCR6ODP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}